# Dynamic Cookie Scanner

ML-powered cookie classification and scanning system with advanced scheduling and analytics.

## ğŸ“ Project Structure

```
dynamic_cookie_scanning_sep29/
â”œâ”€â”€ src/                      # Main source code
â”‚   â”œâ”€â”€ api/                  # FastAPI routers and endpoints
â”‚   â”œâ”€â”€ core/                 # Core configuration and setup
â”‚   â”œâ”€â”€ models/              # Database models (SQLAlchemy)
â”‚   â”œâ”€â”€ services/            # Business logic services
â”‚   â”œâ”€â”€ analytics/           # Analytics and reporting
â”‚   â”œâ”€â”€ ml_classifier/       # ML classification engine
â”‚   â”œâ”€â”€ database/            # Database utilities and connections
â”‚   â””â”€â”€ cache/               # Redis caching layer
â”‚
â”œâ”€â”€ cli/                      # Command-line interface tools
â”‚   â”œâ”€â”€ run_api.py           # Start the API server
â”‚   â”œâ”€â”€ run_celery_worker.py # Start Celery worker
â”‚   â”œâ”€â”€ run_celery_beat.py   # Start Celery beat scheduler
â”‚   â”œâ”€â”€ run_migrations.py    # Run database migrations
â”‚   â””â”€â”€ main.py              # Main CLI entry point
â”‚
â”œâ”€â”€ scripts/                  # Utility scripts
â”‚   â”œâ”€â”€ admin/               # Admin utilities
â”‚   â”‚   â”œâ”€â”€ create_admin_user.py
â”‚   â”‚   â””â”€â”€ generate_dev_token.py
â”‚   â”œâ”€â”€ migrations/          # Database migration SQL files
â”‚   â”œâ”€â”€ ml/                  # ML training and testing scripts
â”‚   â”‚   â”œâ”€â”€ train_model.py
â”‚   â”‚   â”œâ”€â”€ test_classifier.py
â”‚   â”‚   â””â”€â”€ bootstrap_training_data.py
â”‚   â”œâ”€â”€ cookie_scanner.py    # Cookie scanning utilities
â”‚   â”œâ”€â”€ enterprise_scanner.py
â”‚   â””â”€â”€ schedule_manager.py
â”‚
â”œâ”€â”€ tests/                    # Test suite
â”‚   â”œâ”€â”€ integration/         # Integration tests
â”‚   â”œâ”€â”€ performance/         # Performance tests
â”‚   â””â”€â”€ *.py                 # Unit tests
â”‚
â”œâ”€â”€ config/                   # Configuration files
â”‚   â”œâ”€â”€ config.py            # Main configuration
â”‚   â””â”€â”€ logger_setup.py      # Logging configuration
â”‚
â”œâ”€â”€ docker/                   # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ docker-compose.services.yml
â”‚
â”œâ”€â”€ docs/                     # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ API_ENDPOINTS_REFERENCE.md
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ dashboard/                # Next.js dashboard (if applicable)
â”œâ”€â”€ design/                   # Design files and assets
â”œâ”€â”€ logs/                     # Application logs (gitignored)
â”œâ”€â”€ results/                  # Scan results (gitignored)
â”œâ”€â”€ training_data/           # ML training data (gitignored)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ setup.py                 # Package setup
â””â”€â”€ README.md                # This file
```

## ğŸš€ Quick Start

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd dynamic_cookie_scanning_sep29
```

2. Install dependencies:
```bash
pip install -r requirements.txt
# or
./install_dependencies.sh
```

3. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your configuration
```

4. Run database migrations:
```bash
python cli/run_migrations.py
```

### Running the Application

#### Start the API Server
```bash
python cli/run_api.py
```

#### Start Celery Worker
```bash
python cli/run_celery_worker.py
# or
./start_celery_worker.sh
```

#### Start Celery Beat Scheduler
```bash
python cli/run_celery_beat.py
```

### Using Docker

```bash
cd docker
docker-compose up -d
```

## ğŸ“š Documentation

See the [docs](docs/) directory for comprehensive documentation:

- [Architecture Overview](docs/ARCHITECTURE.md)
- [API Endpoints Reference](docs/API_ENDPOINTS_REFERENCE.md)
- [Deployment Guide](docs/DEPLOYMENT_GUIDE.md)
- [Quick Start Guide](docs/QUICK_START.md)
- [Contributing Guidelines](docs/CONTRIBUTING.md)

## ğŸ§ª Running Tests

```bash
# Run all tests
pytest tests/

# Run specific test categories
pytest tests/integration/
pytest tests/performance/

# Run with coverage
pytest --cov=src tests/
```

## ğŸ”§ Development

### Creating Admin User
```bash
python scripts/admin/create_admin_user.py
```

### Training ML Model
```bash
python scripts/ml/train_model.py
```

### Running Scans
```bash
python scripts/cookie_scanner.py --url https://example.com
```

## ğŸ“¦ Key Components

- **API**: FastAPI-based REST API
- **ML Classifier**: Cookie classification using scikit-learn
- **Celery**: Distributed task queue for async operations
- **PostgreSQL**: Primary database
- **Redis**: Caching and Celery broker
- **Dashboard**: Next.js-based web interface

## ğŸ”’ Security

See [SECURITY_FEATURES_IMPLEMENTATION.md](docs/SECURITY_FEATURES_IMPLEMENTATION.md) for security features and best practices.

## ğŸ“Š Monitoring

Prometheus metrics are exposed at `/metrics`. See [PROMETHEUS_METRICS_GUIDE.md](docs/PROMETHEUS_METRICS_GUIDE.md) for details.

## ğŸ¤ Contributing

See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for contribution guidelines.

## ğŸ“„ License

[Your License Here]

## ğŸ“§ Support

For issues and questions, please open a GitHub issue or contact the development team.
